{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcd33aa-0f22-4496-92bb-7f28e058cd64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'rock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16760\\2646191299.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Create a decision tree classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Train the decision tree classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Make predictions on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\RPS_project\\venv\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1149\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\RPS_project\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \"\"\"\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         super()._fit(\n\u001b[0m\u001b[0;32m    960\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\RPS_project\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    238\u001b[0m             check_X_params = dict(\n\u001b[0;32m    239\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             )\n\u001b[0;32m    241\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    243\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             )\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\RPS_project\\venv\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    613\u001b[0m                 \u001b[1;31m# :(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\RPS_project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    912\u001b[0m                         )\n\u001b[0;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m                 raise ValueError(\n\u001b[0;32m    918\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32m~\\Desktop\\RPS_project\\venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\RPS_project\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m         if (\n\u001b[0;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'rock'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the CSV data into a pandas DataFrame\n",
    "file_path = '.csv'  # Replace with your CSV file path\n",
    "column_names = [\n",
    "    \"WRIST_X\",\n",
    "  \"WRIST_Y\",\n",
    "  \"WRIST_Z\",\n",
    "  \"THUMB_CMC_X\",\n",
    "  \"THUMB_CMC_Y\",\n",
    "  \"THUMB_CMC_Z\",\n",
    "  \"THUMB_MCP_X\",\n",
    "  \"THUMB_MCP_Y\",\n",
    "  \"THUMB_MCP_Z\",\n",
    "  \"THUMB_IP_X\",\n",
    "  \"THUMB_IP_Y\",\n",
    "  \"THUMB_IP_Z\",\n",
    "  \"THUMB_TIP_X\",\n",
    "  \"THUMB_TIP_Y\",\n",
    "  \"THUMB_TIP_Z\",\n",
    "  \"INDEX_FINGER_MCP_X\",\n",
    "  \"INDEX_FINGER_MCP_Y\",\n",
    "  \"INDEX_FINGER_MCP_Z\",\n",
    "  \"INDEX_FINGER_PIP_X\",\n",
    "  \"INDEX_FINGER_PIP_Y\",\n",
    "  \"INDEX_FINGER_PIP_Z\",\n",
    "  \"INDEX_FINGER_DIP_X\",\n",
    "  \"INDEX_FINGER_DIP_Y\",\n",
    "  \"INDEX_FINGER_DIP_Z\",\n",
    "  \"INDEX_FINGER_TIP_X\",\n",
    "  \"INDEX_FINGER_TIP_Y\",\n",
    "  \"INDEX_FINGER_TIP_Z\",\n",
    "  \"MIDDLE_FINGER_MCP_X\",\n",
    "  \"MIDDLE_FINGER_MCP_Y\",\n",
    "  \"MIDDLE_FINGER_MCP_Z\",\n",
    "  \"MIDDLE_FINGER_PIP_X\",\n",
    "  \"MIDDLE_FINGER_PIP_Y\",\n",
    "  \"MIDDLE_FINGER_PIP_Z\",\n",
    "  \"MIDDLE_FINGER_DIP_X\",\n",
    "  \"MIDDLE_FINGER_DIP_Y\",\n",
    "  \"MIDDLE_FINGER_DIP_Z\",\n",
    "  \"MIDDLE_FINGER_TIP_X\",\n",
    "  \"MIDDLE_FINGER_TIP_Y\",\n",
    "  \"MIDDLE_FINGER_TIP_Z\",\n",
    "  \"RING_FINGER_MCP_X\",\n",
    "  \"RING_FINGER_MCP_Y\",\n",
    "  \"RING_FINGER_MCP_Z\",\n",
    "  \"RING_FINGER_PIP_X\",\n",
    "  \"RING_FINGER_PIP_Y\",\n",
    "  \"RING_FINGER_PIP_Z\",\n",
    "  \"RING_FINGER_DIP_X\",\n",
    "  \"RING_FINGER_DIP_Y\",\n",
    "  \"RING_FINGER_DIP_Z\",\n",
    "  \"RING_FINGER_TIP_X\",\n",
    "  \"RING_FINGER_TIP_Y\",\n",
    "  \"RING_FINGER_TIP_Z\",\n",
    "  \"PINKY_MCP_X\",\n",
    "  \"PINKY_MCP_Y\",\n",
    "  \"PINKY_MCP_Z\",\n",
    "  \"PINKY_PIP_X\",\n",
    "  \"PINKY_PIP_Y\",\n",
    "  \"PINKY_PIP_Z\",\n",
    "  \"PINKY_DIP_X\",\n",
    "  \"PINKY_DIP_Y\",\n",
    "  \"PINKY_DIP_Z\",\n",
    "  \"PINKY_TIP_X\",\n",
    "  \"PINKY_TIP_Y\",\n",
    "  \"PINKY_TIP_Z\",\n",
    "    'label'  # Last column is the label\n",
    "]\n",
    "hand_landmarks_df = pd.read_csv(file_path, names=column_names)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = hand_landmarks_df.drop('label', axis=1)  # Features (hand landmarks data)\n",
    "y = hand_landmarks_df['label']  # Target variable (gesture labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the decision tree classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of the decision tree classifier: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc06c9b-dd9e-4b70-881f-41f1b08406e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import win32api\n",
    "from math import floor, exp\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mouse\n",
    "import joblib\n",
    "\n",
    "def get_landmark_coords(hand_data, target_landmark):\n",
    "    return [hand_data.landmark[target_landmark].x * image_width, hand_data.landmark[target_landmark].y * image_width,hand_data.landmark[target_landmark].z]\n",
    "\n",
    "def capture_landmarks():\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_hands = mp.solutions.hands\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    directory_path = os.path.join(os.getcwd(), \"gestures\")\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        \n",
    "    landmarks = [\n",
    "        \"WRIST_X\",\n",
    "        \"WRIST_Y\",\n",
    "        \"WRIST_Z\",\n",
    "        \"THUMB_CMC_X\",\n",
    "        \"THUMB_CMC_Y\",\n",
    "        \"THUMB_CMC_Z\",\n",
    "        \"THUMB_MCP_X\",\n",
    "        \"THUMB_MCP_Y\",\n",
    "        \"THUMB_MCP_Z\",\n",
    "        \"THUMB_IP_X\",\n",
    "        \"THUMB_IP_Y\",\n",
    "        \"THUMB_IP_Z\",\n",
    "        \"THUMB_TIP_X\",\n",
    "        \"THUMB_TIP_Y\",\n",
    "        \"THUMB_TIP_Z\",\n",
    "        \"INDEX_FINGER_MCP_X\",\n",
    "        \"INDEX_FINGER_MCP_Y\",\n",
    "        \"INDEX_FINGER_MCP_Z\",\n",
    "        \"INDEX_FINGER_PIP_X\",\n",
    "        \"INDEX_FINGER_PIP_Y\",\n",
    "        \"INDEX_FINGER_PIP_Z\",\n",
    "        \"INDEX_FINGER_DIP_X\",\n",
    "        \"INDEX_FINGER_DIP_Y\",\n",
    "        \"INDEX_FINGER_DIP_Z\",\n",
    "        \"INDEX_FINGER_TIP_X\",\n",
    "        \"INDEX_FINGER_TIP_Y\",\n",
    "        \"INDEX_FINGER_TIP_Z\",\n",
    "        \"MIDDLE_FINGER_MCP_X\",\n",
    "        \"MIDDLE_FINGER_MCP_Y\",\n",
    "        \"MIDDLE_FINGER_MCP_Z\",\n",
    "        \"MIDDLE_FINGER_PIP_X\",\n",
    "        \"MIDDLE_FINGER_PIP_Y\",\n",
    "        \"MIDDLE_FINGER_PIP_Z\",\n",
    "        \"MIDDLE_FINGER_DIP_X\",\n",
    "        \"MIDDLE_FINGER_DIP_Y\",\n",
    "        \"MIDDLE_FINGER_DIP_Z\",\n",
    "        \"MIDDLE_FINGER_TIP_X\",\n",
    "        \"MIDDLE_FINGER_TIP_Y\",\n",
    "        \"MIDDLE_FINGER_TIP_Z\",\n",
    "        \"RING_FINGER_MCP_X\",\n",
    "        \"RING_FINGER_MCP_Y\",\n",
    "        \"RING_FINGER_MCP_Z\",\n",
    "        \"RING_FINGER_PIP_X\",\n",
    "        \"RING_FINGER_PIP_Y\",\n",
    "        \"RING_FINGER_PIP_Z\",\n",
    "        \"RING_FINGER_DIP_X\",\n",
    "        \"RING_FINGER_DIP_Y\",\n",
    "        \"RING_FINGER_DIP_Z\",\n",
    "        \"RING_FINGER_TIP_X\",\n",
    "        \"RING_FINGER_TIP_Y\",\n",
    "        \"RING_FINGER_TIP_Z\",\n",
    "        \"PINKY_MCP_X\",\n",
    "        \"PINKY_MCP_Y\",\n",
    "        \"PINKY_MCP_Z\",\n",
    "        \"PINKY_PIP_X\",\n",
    "        \"PINKY_PIP_Y\",\n",
    "        \"PINKY_PIP_Z\",\n",
    "        \"PINKY_DIP_X\",\n",
    "        \"PINKY_DIP_Y\",\n",
    "        \"PINKY_DIP_Z\",\n",
    "        \"PINKY_TIP_X\",\n",
    "        \"PINKY_TIP_Y\",\n",
    "        \"PINKY_TIP_Z\"\n",
    "    ]\n",
    "\n",
    "    # pipe = joblib.load(\"./clf_gini_model.sav\")\n",
    "    pipe = joblib.load(\"./clf_entropy_model.sav\")\n",
    "    \n",
    "    last_5_frames_values = []\n",
    "\n",
    "    with mp_hands.Hands(\n",
    "        model_complexity=1,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5,\n",
    "        max_num_hands=1 # Can change\n",
    "    ) as hands:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            # h, w, c = frame.shape()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image)\n",
    "\n",
    "            # Draw the hand annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            global image_height, image_width\n",
    "            image_height, image_width, _ = image.shape\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    # MOUSE MOVEMENT\n",
    "                    index_x = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP].x\n",
    "                    index_y = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP].y\n",
    "                    screen_width = win32api.GetSystemMetrics(0)\n",
    "                    screen_height = win32api.GetSystemMetrics(1)\n",
    "\n",
    "                    \n",
    "                    # win32api.SetCursorPos(\n",
    "                    #     (\n",
    "                    #         floor(screen_width - index_x * screen_width),\n",
    "                    #         floor(index_y * screen_height)\n",
    "                    #     )\n",
    "                    # )\n",
    "                    # print(f\"({index_x * screen_width}, {index_y * screen_height})\")\n",
    "                    hand_landmarks_data = [\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.WRIST),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.THUMB_CMC),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.THUMB_MCP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.THUMB_IP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.THUMB_TIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.INDEX_FINGER_MCP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.INDEX_FINGER_PIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.INDEX_FINGER_DIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.INDEX_FINGER_TIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.MIDDLE_FINGER_MCP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.MIDDLE_FINGER_PIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.MIDDLE_FINGER_DIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.MIDDLE_FINGER_TIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.RING_FINGER_MCP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.RING_FINGER_PIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.RING_FINGER_DIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.RING_FINGER_TIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.PINKY_MCP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.PINKY_PIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.PINKY_DIP),\n",
    "                        *get_landmark_coords(hand_landmarks, mp_hands.HandLandmark.PINKY_TIP),\n",
    "                    ]\n",
    "                    \n",
    "                    live_data_2d = np.array(hand_landmarks_data).reshape(1, -1)\n",
    "                    pred = pd.Series(pipe.predict(live_data_2d, landmarks))\n",
    "                    last_5_frames_values.append(pred.iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "                    if pred.iloc[0] != \"none\" or last_5_frames_values.count(\"none\") < 1:\n",
    "                        originx = screen_height/2\n",
    "                        originy = screen_width/2\n",
    "                        origin_index_x = index_x - 0.5\n",
    "                        origin_index_y = index_y - 0.5\n",
    "                        mouse.move(\n",
    "                            # floor((screen_width / 2) + (index_x - screen_width)),\n",
    "                            # floor((screen_height / 2) + (index_y - screen_height)),\n",
    "                            floor((screen_width/2) - (origin_index_x * screen_width)*2),\n",
    "                            floor((screen_height/2) + (origin_index_y * screen_height)*2),\n",
    "                            absolute=True, duration=0.1\n",
    "                        )\n",
    "\n",
    "                    print(last_5_frames_values)\n",
    "                    if len(last_5_frames_values) >= 5:\n",
    "                        if last_5_frames_values.count(\"click\") > last_5_frames_values.count(\"click_track\"):\n",
    "                            mouse.click(\"left\")\n",
    "                        last_5_frames_values.clear()\n",
    "\n",
    "                    # mp_drawing.draw_landmarks(\n",
    "                    #     image,\n",
    "                    #     hand_landmarks,\n",
    "                    #     mp_hands.HAND_CONNECTIONS,\n",
    "                    #     mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    #     mp_drawing_styles.get_default_hand_connections_style(),\n",
    "                    # )\n",
    "            \n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow(\"MediaPipe Hands\", cv2.flip(image, 1))\n",
    "\n",
    "            # Escape key or close button\n",
    "            if (\n",
    "                cv2.waitKey(5) & 0xFF == 27\n",
    "                or cv2.getWindowProperty(\"MediaPipe Hands\", cv2.WND_PROP_VISIBLE)\n",
    "                < 1\n",
    "            ):\n",
    "                break\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "capture_landmarks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
